{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 4: Instrumental Variables\n",
    "\n",
    "This lab covers instrumental variables (IV) estimation through two applications:\n",
    "\n",
    "- **Part 1**: Children's Television and Educational Performance (Sesame Street experiment)\n",
    "- **Part 2**: Do Institutions Cause Growth? (Acemoglu, Johnson & Robinson, 2001)\n",
    "\n",
    "We estimate the Intent-to-Treat (ITT) effect, the Local Average Treatment Effect (LATE) via the Wald estimator, and two-stage least squares (2SLS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels.iv import IV2SLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Children's Television and Educational Performance\n",
    "\n",
    "In the early 1970s, the Educational Testing Service conducted an experiment to evaluate the educational impact of Sesame Street. Children were randomly assigned to receive encouragement to watch the show, but compliance was imperfect: some encouraged children did not watch, and some non-encouraged children did.\n",
    "\n",
    "- **Instrument** ($Z$): `encouraged` (random assignment to watch)\n",
    "- **Treatment** ($D$): `watched` (actually watching Sesame Street)\n",
    "- **Outcome** ($Y$): `letters` (post-test literacy score, 0-63)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (240, 3)\n",
      "\n",
      "Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>encouraged</th>\n",
       "      <th>watched</th>\n",
       "      <th>letters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>240.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.633333</td>\n",
       "      <td>0.775000</td>\n",
       "      <td>26.741667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.482902</td>\n",
       "      <td>0.418455</td>\n",
       "      <td>13.375176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>15.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>39.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>63.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       encouraged     watched     letters\n",
       "count  240.000000  240.000000  240.000000\n",
       "mean     0.633333    0.775000   26.741667\n",
       "std      0.482902    0.418455   13.375176\n",
       "min      0.000000    0.000000    0.000000\n",
       "25%      0.000000    1.000000   15.000000\n",
       "50%      1.000000    1.000000   23.000000\n",
       "75%      1.000000    1.000000   39.250000\n",
       "max      1.000000    1.000000   63.000000"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sesame = pd.read_csv('../data/lab4/iv_part1.csv')\n",
    "\n",
    "print(f'Shape: {sesame.shape}')\n",
    "print(f'\\nSummary:')\n",
    "sesame.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: Unit Types\n",
    "\n",
    "In the IV framework with imperfect compliance, we distinguish four types:\n",
    "\n",
    "| Type | $D(Z=1)$ | $D(Z=0)$ | Description |\n",
    "|------|-----------|-----------|-------------|\n",
    "| **Compliers** | Watch | Don't watch | Respond to encouragement |\n",
    "| **Always-takers** | Watch | Watch | Would watch regardless |\n",
    "| **Never-takers** | Don't watch | Don't watch | Would not watch regardless |\n",
    "| **Defiers** | Don't watch | Watch | Do the opposite (assumed away) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Compliance Analysis\n",
    "\n",
    "Examine the cross-tabulation of assignment and actual treatment to understand the extent of non-compliance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Counts ===\n",
      "                Not watched  Watched  Total\n",
      "Not encouraged           40       48     88\n",
      "Encouraged               14      138    152\n",
      "Total                    54      186    240\n",
      "\n",
      "=== Proportions (by row) ===\n",
      "                Not watched  Watched\n",
      "Not encouraged       0.4545   0.5455\n",
      "Encouraged           0.0921   0.9079\n"
     ]
    }
   ],
   "source": [
    "# Cross-tabulation\n",
    "print('=== Counts ===')\n",
    "ct = pd.crosstab(sesame['encouraged'], sesame['watched'], margins=True)\n",
    "ct.index = ['Not encouraged', 'Encouraged', 'Total']\n",
    "ct.columns = ['Not watched', 'Watched', 'Total']\n",
    "print(ct)\n",
    "\n",
    "print('\\n=== Proportions (by row) ===')\n",
    "pt = pd.crosstab(sesame['encouraged'], sesame['watched'], normalize='index')\n",
    "pt.index = ['Not encouraged', 'Encouraged']\n",
    "pt.columns = ['Not watched', 'Watched']\n",
    "print(pt.round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two-sided non-compliance: some encouraged children did not watch (non-compliers in the treatment group), and some non-encouraged children watched anyway (always-takers in the control group)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: Proportion of Compliers\n",
    "\n",
    "Under the monotonicity assumption (no defiers):\n",
    "\n",
    "$$\\pi_c = E[D_i | Z_i = 1] - E[D_i | Z_i = 0]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(watched | encouraged):     0.9079\n",
      "P(watched | not encouraged): 0.5455\n",
      "Proportion of compliers:     0.3624\n"
     ]
    }
   ],
   "source": [
    "d_z1 = sesame.loc[sesame['encouraged'] == 1, 'watched'].mean()\n",
    "d_z0 = sesame.loc[sesame['encouraged'] == 0, 'watched'].mean()\n",
    "proportion_compliers = d_z1 - d_z0\n",
    "\n",
    "print(f'P(watched | encouraged):     {d_z1:.4f}')\n",
    "print(f'P(watched | not encouraged): {d_z0:.4f}')\n",
    "print(f'Proportion of compliers:     {proportion_compliers:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Intent-to-Treat (ITT) Effect\n",
    "\n",
    "The ITT estimates the causal effect of *assignment* (not treatment) on the outcome:\n",
    "\n",
    "$$\\text{ITT} = E[Y_i | Z_i = 1] - E[Y_i | Z_i = 0]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean letters (encouraged):     27.7961\n",
      "Mean letters (not encouraged): 24.9205\n",
      "ITT:                           2.8756\n",
      "\n",
      "Verification via OLS:\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     24.9205      1.421     17.536      0.000      22.121      27.720\n",
      "encouraged     2.8756      1.786      1.610      0.109      -0.642       6.393\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "y_z1 = sesame.loc[sesame['encouraged'] == 1, 'letters'].mean()\n",
    "y_z0 = sesame.loc[sesame['encouraged'] == 0, 'letters'].mean()\n",
    "itt = y_z1 - y_z0\n",
    "\n",
    "print(f'Mean letters (encouraged):     {y_z1:.4f}')\n",
    "print(f'Mean letters (not encouraged): {y_z0:.4f}')\n",
    "print(f'ITT:                           {itt:.4f}')\n",
    "\n",
    "print('\\nVerification via OLS:')\n",
    "itt_model = smf.ols('letters ~ encouraged', data=sesame).fit()\n",
    "print(itt_model.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ITT combines the effect of the treatment on those who comply with the dilution from non-compliers. Being *encouraged* to watch Sesame Street increases literacy scores by approximately 3 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions 6-7: Local Average Treatment Effect (LATE)\n",
    "\n",
    "The LATE estimates the effect of actually *watching* for compliers, using the Wald estimator:\n",
    "\n",
    "$$\\text{LATE} = \\frac{\\text{ITT}}{\\pi_c} = \\frac{E[Y_i|Z_i=1] - E[Y_i|Z_i=0]}{E[D_i|Z_i=1] - E[D_i|Z_i=0]}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ITT:                     2.8756\n",
      "Proportion of compliers: 0.3624\n",
      "LATE (Wald estimator):   7.9340\n"
     ]
    }
   ],
   "source": [
    "late = itt / proportion_compliers\n",
    "\n",
    "print(f'ITT:                     {itt:.4f}')\n",
    "print(f'Proportion of compliers: {proportion_compliers:.4f}')\n",
    "print(f'LATE (Wald estimator):   {late:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LATE is substantially larger than the ITT because it scales up to account for the dilution from non-compliers. For children who complied with encouragement, watching Sesame Street increased literacy scores by approximately 8 points."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8: ITT vs. LATE\n",
    "\n",
    "The **LATE** is of greater interest to Sesame Street's producers because it isolates the causal effect of *actually watching* the show, whereas the ITT conflates the treatment effect with non-compliance rates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9: Exclusion Restriction\n",
    "\n",
    "The exclusion restriction requires that encouragement affects literacy *only through* its effect on watching behavior. This is plausible: being told to watch Sesame Street should not directly improve literacy unless the child actually watches. However, one could argue that encouragement might prompt parents to engage in other educational activities, potentially violating the restriction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: Do Institutions Cause Growth?\n",
    "\n",
    "**Acemoglu, D., Johnson, S. & Robinson, J.A. (2001).** *The Colonial Origins of Comparative Development: An Empirical Investigation.* American Economic Review, 91(5), 1369-1401.\n",
    "\n",
    "AJR argue that European colonial settlers established different types of institutions depending on local disease environments. Where settler mortality was high, extractive institutions were established; where it was low, settlers replicated inclusive European institutions.\n",
    "\n",
    "- **Outcome** ($Y$): `GDP` (log GDP per capita)\n",
    "- **Treatment** ($D$): `Exprop` (protection against expropriation, a proxy for institutional quality)\n",
    "- **Instrument** ($Z$): `logMort` (log settler mortality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (64, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>Exprop</th>\n",
       "      <th>Mort</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Neo</th>\n",
       "      <th>Africa</th>\n",
       "      <th>Asia</th>\n",
       "      <th>Namer</th>\n",
       "      <th>Samer</th>\n",
       "      <th>logMort</th>\n",
       "      <th>Latitude2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "      <td>64.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8.062500</td>\n",
       "      <td>6.516094</td>\n",
       "      <td>245.911094</td>\n",
       "      <td>0.190483</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.421875</td>\n",
       "      <td>0.140625</td>\n",
       "      <td>0.218750</td>\n",
       "      <td>0.171875</td>\n",
       "      <td>4.646749</td>\n",
       "      <td>0.057002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.043701</td>\n",
       "      <td>1.468841</td>\n",
       "      <td>472.623943</td>\n",
       "      <td>0.145075</td>\n",
       "      <td>0.243975</td>\n",
       "      <td>0.497763</td>\n",
       "      <td>0.350382</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.380254</td>\n",
       "      <td>1.252543</td>\n",
       "      <td>0.086039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.110000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>8.550000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.145931</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.302500</td>\n",
       "      <td>5.617500</td>\n",
       "      <td>68.900000</td>\n",
       "      <td>0.088900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.232656</td>\n",
       "      <td>0.007903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.950000</td>\n",
       "      <td>6.475000</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>0.161150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.358630</td>\n",
       "      <td>0.026000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.852500</td>\n",
       "      <td>7.352500</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.267100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.480639</td>\n",
       "      <td>0.071343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.220000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>2940.000000</td>\n",
       "      <td>0.666700</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.986165</td>\n",
       "      <td>0.444489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             GDP     Exprop         Mort   Latitude        Neo     Africa  \\\n",
       "count  64.000000  64.000000    64.000000  64.000000  64.000000  64.000000   \n",
       "mean    8.062500   6.516094   245.911094   0.190483   0.062500   0.421875   \n",
       "std     1.043701   1.468841   472.623943   0.145075   0.243975   0.497763   \n",
       "min     6.110000   3.500000     8.550000   0.000000   0.000000   0.000000   \n",
       "25%     7.302500   5.617500    68.900000   0.088900   0.000000   0.000000   \n",
       "50%     7.950000   6.475000    78.150000   0.161150   0.000000   0.000000   \n",
       "75%     8.852500   7.352500   240.000000   0.267100   0.000000   1.000000   \n",
       "max    10.220000  10.000000  2940.000000   0.666700   1.000000   1.000000   \n",
       "\n",
       "            Asia      Namer      Samer    logMort  Latitude2  \n",
       "count  64.000000  64.000000  64.000000  64.000000  64.000000  \n",
       "mean    0.140625   0.218750   0.171875   4.646749   0.057002  \n",
       "std     0.350382   0.416667   0.380254   1.252543   0.086039  \n",
       "min     0.000000   0.000000   0.000000   2.145931   0.000000  \n",
       "25%     0.000000   0.000000   0.000000   4.232656   0.007903  \n",
       "50%     0.000000   0.000000   0.000000   4.358630   0.026000  \n",
       "75%     0.000000   0.000000   0.000000   5.480639   0.071343  \n",
       "max     1.000000   1.000000   1.000000   7.986165   0.444489  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ajr = pd.read_csv('../data/lab4/iv_part2.csv')\n",
    "\n",
    "print(f'Shape: {ajr.shape}')\n",
    "ajr.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: OLS Estimates (Biased)\n",
    "\n",
    "The OLS estimate of institutional quality on GDP is likely biased due to reverse causality and omitted variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== OLS without covariates ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      4.6609      0.409     11.402      0.000       3.844       5.478\n",
      "Exprop         0.5220      0.061      8.527      0.000       0.400       0.644\n",
      "==============================================================================\n",
      "\n",
      "=== OLS with regional controls ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.9879      0.612      9.792      0.000       4.764       7.212\n",
      "Exprop         0.4234      0.058      7.313      0.000       0.307       0.539\n",
      "Africa        -1.1363      0.397     -2.862      0.006      -1.931      -0.342\n",
      "Asia          -0.8496      0.405     -2.100      0.040      -1.659      -0.040\n",
      "Namer         -0.2230      0.396     -0.563      0.576      -1.016       0.570\n",
      "Samer         -0.2125      0.402     -0.528      0.600      -1.018       0.593\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "ols1 = smf.ols('GDP ~ Exprop', data=ajr).fit()\n",
    "ols2 = smf.ols('GDP ~ Exprop + Africa + Asia + Namer + Samer', data=ajr).fit()\n",
    "\n",
    "print('=== OLS without covariates ===')\n",
    "print(ols1.summary().tables[1])\n",
    "print(f'\\n=== OLS with regional controls ===')\n",
    "print(ols2.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3: Reduced Form\n",
    "\n",
    "The reduced form regresses the outcome directly on the instrument. This estimates the ITT: the total effect of settler mortality on GDP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Reduced form without covariates ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     10.6943      0.373     28.644      0.000       9.948      11.441\n",
      "logMort       -0.5664      0.078     -7.297      0.000      -0.722      -0.411\n",
      "==============================================================================\n",
      "\n",
      "=== Reduced form with regional controls ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     10.6631      0.476     22.401      0.000       9.710      11.616\n",
      "logMort       -0.4093      0.098     -4.165      0.000      -0.606      -0.213\n",
      "Africa        -1.0687      0.536     -1.992      0.051      -2.142       0.005\n",
      "Asia          -0.9002      0.501     -1.795      0.078      -1.904       0.103\n",
      "Namer         -0.3143      0.498     -0.632      0.530      -1.310       0.682\n",
      "Samer         -0.3047      0.503     -0.606      0.547      -1.311       0.701\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "rf1 = smf.ols('GDP ~ logMort', data=ajr).fit()\n",
    "rf2 = smf.ols('GDP ~ logMort + Africa + Asia + Namer + Samer', data=ajr).fit()\n",
    "\n",
    "print('=== Reduced form without covariates ===')\n",
    "print(rf1.summary().tables[1])\n",
    "print(f'\\n=== Reduced form with regional controls ===')\n",
    "print(rf2.summary().tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4: First Stage and F-test for Weak Instruments\n",
    "\n",
    "The first stage regresses the endogenous treatment on the instrument. The F-statistic tests instrument relevance; a common rule of thumb requires $F > 10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== First stage (no covariates) ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      9.3659      0.611     15.339      0.000       8.145      10.586\n",
      "logMort       -0.6133      0.127     -4.831      0.000      -0.867      -0.360\n",
      "==============================================================================\n",
      "F-statistic: 23.34\n",
      "\n",
      "=== First stage (with covariates) ===\n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      9.7945      0.843     11.623      0.000       8.108      11.481\n",
      "logMort       -0.4381      0.174     -2.518      0.015      -0.786      -0.090\n",
      "Africa        -1.5053      0.950     -1.585      0.118      -3.406       0.396\n",
      "Asia          -0.8999      0.888     -1.014      0.315      -2.676       0.877\n",
      "Namer         -1.2620      0.881     -1.433      0.157      -3.025       0.501\n",
      "Samer         -1.1913      0.890     -1.339      0.186      -2.972       0.590\n",
      "==============================================================================\n",
      "\n",
      "F-test for instrument (with covariates): F = 6.34, p = 0.0146\n",
      "F < 10 suggests the instrument may be weak when controlling for region.\n"
     ]
    }
   ],
   "source": [
    "# First stage without covariates\n",
    "fs1 = smf.ols('Exprop ~ logMort', data=ajr).fit()\n",
    "print('=== First stage (no covariates) ===')\n",
    "print(fs1.summary().tables[1])\n",
    "print(f'F-statistic: {fs1.fvalue:.2f}')\n",
    "\n",
    "print()\n",
    "\n",
    "# First stage with covariates\n",
    "fs_restricted = smf.ols('Exprop ~ Africa + Asia + Namer + Samer', data=ajr).fit()\n",
    "fs_full = smf.ols('Exprop ~ logMort + Africa + Asia + Namer + Samer', data=ajr).fit()\n",
    "\n",
    "print('=== First stage (with covariates) ===')\n",
    "print(fs_full.summary().tables[1])\n",
    "\n",
    "# F-test for instrument: compare model with and without logMort\n",
    "from scipy.stats import f as f_dist\n",
    "n = len(ajr)\n",
    "k_full = len(fs_full.params)\n",
    "k_restricted = len(fs_restricted.params)\n",
    "f_stat = ((fs_restricted.ssr - fs_full.ssr) / (k_full - k_restricted)) / (fs_full.ssr / (n - k_full))\n",
    "f_pval = 1 - f_dist.cdf(f_stat, k_full - k_restricted, n - k_full)\n",
    "\n",
    "print(f'\\nF-test for instrument (with covariates): F = {f_stat:.2f}, p = {f_pval:.4f}')\n",
    "print(f'F < 10 suggests the instrument may be weak when controlling for region.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5: Two-Stage Least Squares (2SLS)\n",
    "\n",
    "Estimate the LATE using 2SLS via the `linearmodels` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 2SLS without covariates ===\n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "const          2.0448     0.9837     2.0786     0.0377      0.1167      3.9728\n",
      "Exprop         0.9235     0.1499     6.1590     0.0000      0.6296      1.2174\n",
      "==============================================================================\n",
      "\n",
      "=== 2SLS with regional controls ===\n",
      "                             Parameter Estimates                              \n",
      "==============================================================================\n",
      "            Parameter  Std. Err.     T-stat    P-value    Lower CI    Upper CI\n",
      "------------------------------------------------------------------------------\n",
      "Africa         0.3376     0.9361     0.3606     0.7184     -1.4972      2.1724\n",
      "Asia          -0.0595     0.7093    -0.0839     0.9331     -1.4498      1.3307\n",
      "Namer          0.8647     0.7926     1.0909     0.2753     -0.6888      2.4182\n",
      "Samer          0.8083     0.7770     1.0403     0.2982     -0.7146      2.3311\n",
      "const          1.5129     2.4058     0.6289     0.5294     -3.2023      6.2282\n",
      "Exprop         0.9342     0.2687     3.4769     0.0005      0.4076      1.4608\n",
      "==============================================================================\n"
     ]
    }
   ],
   "source": [
    "# 2SLS without covariates\n",
    "iv1 = IV2SLS(\n",
    "    dependent=ajr['GDP'],\n",
    "    exog=pd.DataFrame({'const': 1}, index=ajr.index),\n",
    "    endog=ajr[['Exprop']],\n",
    "    instruments=ajr[['logMort']]\n",
    ").fit(cov_type='unadjusted')\n",
    "\n",
    "print('=== 2SLS without covariates ===')\n",
    "print(iv1.summary.tables[1])\n",
    "\n",
    "print()\n",
    "\n",
    "# 2SLS with covariates\n",
    "exog_vars = ajr[['Africa', 'Asia', 'Namer', 'Samer']].copy()\n",
    "exog_vars['const'] = 1\n",
    "\n",
    "iv2 = IV2SLS(\n",
    "    dependent=ajr['GDP'],\n",
    "    exog=exog_vars,\n",
    "    endog=ajr[['Exprop']],\n",
    "    instruments=ajr[['logMort']]\n",
    ").fit(cov_type='unadjusted')\n",
    "\n",
    "print('=== 2SLS with regional controls ===')\n",
    "print(iv2.summary.tables[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IV estimates suggest a large and statistically significant causal effect of institutions on GDP growth. A one-unit increase in protection against expropriation causes approximately a 0.9 unit increase in log GDP per capita. The IV estimates are larger than OLS, consistent with OLS being attenuated by measurement error in institutional quality."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
